The OpenAI Python library provides access to the OpenAI REST API for Python 3.8+ applications. It includes type definitions for request parameters and response fields, and offers both synchronous and asynchronous clients powered by `httpx`. The library is generated from OpenAI's OpenAPI specification using Stainless.

### Installation
To install the library from PyPI:
```bash
pip install openai
```

### Usage
To interact with OpenAI models, use the `Responses API`:
```python
import os
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

response = client.responses.create(
    model="gpt-4o",
    instructions="You are a coding assistant that talks like a pirate.",
    input="How do I check if a Python object is an instance of a class?",
)

print(response.output_text)
```

### Async Usage
For asynchronous operations, use `AsyncOpenAI`:
```python
import os
import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

async def main():
    response = await client.responses.create(
        model="gpt-4o",
        input="Explain disestablishmentarianism to a smart five year old."
    )
    print(response.output_text)

asyncio.run(main())
```

### Streaming Responses
The library supports streaming responses using Server Side Events (SSE):
```python
from openai import OpenAI

client = OpenAI()

stream = client.responses.create(
    model="gpt-4o",
    input="Write a one-sentence bedtime story about a unicorn.",
    stream=True,
)

for event in stream:
    print(event)
```

### Realtime API Beta
The Realtime API supports low-latency, multi-modal conversational experiences:
```python
import asyncio
from openai import AsyncOpenAI

async def main():
    client = AsyncOpenAI()
    async with client.beta.realtime.connect(model="gpt-4o-realtime-preview") as connection:
        await connection.session.update(session={'modalities': ['text']})
        await connection.conversation.item.create(
            item={"type": "message", "role": "user", "content": [{"type": "input_text", "text": "Say hello!"}]}
        )
        await connection.response.create()

        async for event in connection:
            if event.type == 'response.text.delta':
                print(event.delta, flush=True, end="")
            elif event.type == 'response.text.done':
                print()
            elif event.type == "response.done":
                break

asyncio.run(main())
```

### Error Handling
Errors are handled using specific exceptions:
```python
import openai
from openai import OpenAI

client = OpenAI()

try:
    client.fine_tuning.jobs.create(
        model="gpt-4o",
        training_file="file-abc123",
    )
except openai.APIConnectionError as e:
    print("The server could not be reached")
    print(e.__cause__)
except openai.RateLimitError as e:
    print("A 429 status code was received; we should back off a bit.")
except openai.APIStatusError as e:
    print("Another non-200-range status code was received")
    print(e.status_code)
    print(e.response)
```

### Advanced Features
- **Logging**: Enable logging by setting `OPENAI_LOG` to `info` or `debug`.
- **Custom HTTP Client**: Override the `httpx` client for custom configurations.
- **Azure OpenAI**: Use `AzureOpenAI` class for Azure-specific configurations.

### Contributing
Contributions are welcome. See the contributing documentation for more details.

### Security
Report security issues to Stainless Software Inc. at `security@stainless.com`.

For more detailed information, refer to the full API documentation in `api.md`.